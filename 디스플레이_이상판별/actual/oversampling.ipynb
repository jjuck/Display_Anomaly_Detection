{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receip No Collect Result_Dam                       int64\n",
      "1st Pressure 1st Pressure Unit Time_AutoClave      int64\n",
      "3rd Pressure Collect Result_AutoClave            float64\n",
      "Chamber Temp. Unit Time_AutoClave                  int64\n",
      "Receip No Collect Result_Fill1                     int64\n",
      "Receip No Collect Result_Fill2                     int64\n",
      "Condition1                                         int32\n",
      "Condition2                                         int32\n",
      "target                                             int32\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Receip No Collect Result_Dam</th>\n",
       "      <th>1st Pressure 1st Pressure Unit Time_AutoClave</th>\n",
       "      <th>3rd Pressure Collect Result_AutoClave</th>\n",
       "      <th>Chamber Temp. Unit Time_AutoClave</th>\n",
       "      <th>Receip No Collect Result_Fill1</th>\n",
       "      <th>Receip No Collect Result_Fill2</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0.499</td>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.498</td>\n",
       "      <td>483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.498</td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.500</td>\n",
       "      <td>483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0.498</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40501</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.500</td>\n",
       "      <td>483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40502</th>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0.498</td>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40503</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.498</td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40504</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>0.499</td>\n",
       "      <td>483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40505</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.498</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40506 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Receip No Collect Result_Dam  \\\n",
       "0                                 1   \n",
       "1                                 1   \n",
       "2                                 1   \n",
       "3                                 1   \n",
       "4                                 1   \n",
       "...                             ...   \n",
       "40501                             1   \n",
       "40502                             1   \n",
       "40503                             1   \n",
       "40504                             1   \n",
       "40505                             1   \n",
       "\n",
       "       1st Pressure 1st Pressure Unit Time_AutoClave  \\\n",
       "0                                                240   \n",
       "1                                                241   \n",
       "2                                                241   \n",
       "3                                                241   \n",
       "4                                                240   \n",
       "...                                              ...   \n",
       "40501                                            241   \n",
       "40502                                            240   \n",
       "40503                                            241   \n",
       "40504                                            241   \n",
       "40505                                            300   \n",
       "\n",
       "       3rd Pressure Collect Result_AutoClave  \\\n",
       "0                                      0.499   \n",
       "1                                      0.498   \n",
       "2                                      0.498   \n",
       "3                                      0.500   \n",
       "4                                      0.498   \n",
       "...                                      ...   \n",
       "40501                                  0.500   \n",
       "40502                                  0.498   \n",
       "40503                                  0.498   \n",
       "40504                                  0.499   \n",
       "40505                                  0.498   \n",
       "\n",
       "       Chamber Temp. Unit Time_AutoClave  Receip No Collect Result_Fill1  \\\n",
       "0                                    361                               1   \n",
       "1                                    483                               1   \n",
       "2                                    363                               1   \n",
       "3                                    483                               1   \n",
       "4                                    480                               1   \n",
       "...                                  ...                             ...   \n",
       "40501                                483                               1   \n",
       "40502                                361                               1   \n",
       "40503                                363                               1   \n",
       "40504                                483                               1   \n",
       "40505                                480                               1   \n",
       "\n",
       "       Receip No Collect Result_Fill2  Condition1  Condition2  target  \n",
       "0                                   1           0           0       1  \n",
       "1                                   1           0           0       1  \n",
       "2                                   1           0           0       1  \n",
       "3                                   1           0           0       1  \n",
       "4                                   1           0           0       1  \n",
       "...                               ...         ...         ...     ...  \n",
       "40501                               1           0           0       1  \n",
       "40502                               1           0           0       1  \n",
       "40503                               1           0           0       1  \n",
       "40504                               1           0           0       1  \n",
       "40505                               1           0           0       0  \n",
       "\n",
       "[40506 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE\n",
    "import catboost as cb\n",
    "\n",
    "ROOT_DIR = \"data\"\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(ROOT_DIR, \"train_mod.csv\"))\n",
    "\n",
    "def cat2num(X):\n",
    "    non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "    encoded_columns = {}\n",
    "\n",
    "    for column in non_numeric_columns:\n",
    "        encoder = LabelEncoder()\n",
    "        encoded_columns[column] = encoder.fit_transform(X[column])\n",
    "\n",
    "    encoded_df = pd.DataFrame(encoded_columns, index=X.index)\n",
    "    X = X.drop(columns=non_numeric_columns)\n",
    "    X = pd.concat([X, encoded_df], axis=1)\n",
    "\n",
    "    return X\n",
    "\n",
    "def condition(df):\n",
    "    df = cat2num(df)\n",
    "    \n",
    "    df['Condition1'] = df['Head Clean Position Z Collect Result_Dam'] <= 120\n",
    "    df['Condition1'] = df['Condition1'].astype(int)\n",
    "    \n",
    "    df['Condition2'] = (df['HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'] >= 284) & (df['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] >= 1000)\n",
    "    df['Condition2'] = df['Condition2'].astype(int)\n",
    "\n",
    "    try:\n",
    "        df = df[['Receip No Collect Result_Dam', \n",
    "                 '1st Pressure 1st Pressure Unit Time_AutoClave', \n",
    "                 '3rd Pressure Collect Result_AutoClave', \n",
    "                 'Chamber Temp. Unit Time_AutoClave', \n",
    "                 'Receip No Collect Result_Fill1', \n",
    "                 'Receip No Collect Result_Fill2',\n",
    "                 'Condition1', \n",
    "                 'Condition2',\n",
    "                 'target']]\n",
    "    except KeyError:\n",
    "        df = df[['Receip No Collect Result_Dam', \n",
    "                 '1st Pressure 1st Pressure Unit Time_AutoClave', \n",
    "                 '3rd Pressure Collect Result_AutoClave', \n",
    "                 'Chamber Temp. Unit Time_AutoClave', \n",
    "                 'Receip No Collect Result_Fill1', \n",
    "                 'Receip No Collect Result_Fill2',\n",
    "                 'Condition1', \n",
    "                 'Condition2']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data = condition(train_data)\n",
    "\n",
    "print(train_data.dtypes)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = [col for col in train_data.columns if col != 'target']\n",
    "train_data[columns_to_scale] = scaler.fit_transform(train_data[columns_to_scale])\n",
    "\n",
    "# SMOTE for oversampling the minority class\n",
    "X = train_data.drop(columns=['target'])\n",
    "y = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    # F1 Score: 0.6494\n",
    "    # Recall: 0.7532\n",
    "    # Accuracy: 0.5906\n",
    "    # Precision: 0.5707\n",
    "\n",
    "# SMOTENC: 연속형 및 범주형 데이터 혼합 시 사용\n",
    "categorical_features = [0, 4, 5, 6, 7]  # 범주형 특성의 인덱스\n",
    "smote_nc = SMOTENC(categorical_features=categorical_features, sampling_strategy='auto', random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
    "    # F1 Score: 0.6477\n",
    "    # Recall: 0.7496\n",
    "    # Accuracy: 0.5895\n",
    "    # Precision: 0.5702\n",
    "\n",
    "\n",
    "# SMOTEN: 범주형 데이터에만 적용\n",
    "smote_n = SMOTEN(sampling_strategy='auto', random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = smote_n.fit_resample(X, y)\n",
    "    # F1 Score: 0.6519\n",
    "    # Recall: 0.7526\n",
    "    # Accuracy: 0.5954\n",
    "    # Precision: 0.5749\n",
    "\n",
    "\n",
    "# BorderlineSMOTE: 경계선 근처의 샘플을 이용한 SMOTE 변형\n",
    "borderline_smote = BorderlineSMOTE(sampling_strategy='auto', random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = borderline_smote.fit_resample(X, y)\n",
    "    # F1 Score: 0.7891\n",
    "    # Recall: 0.6937\n",
    "    # Accuracy: 0.8133\n",
    "    # Precision: 0.9149\n",
    "\n",
    "# SVMSMOTE: SVM을 이용한 SMOTE 변형\n",
    "svm_smote = SVMSMOTE(sampling_strategy='auto', random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = svm_smote.fit_resample(X, y)\n",
    "    # F1 Score: 0.8185\n",
    "    # Recall: 0.8232\n",
    "    # Accuracy: 0.8162\n",
    "    # Precision: 0.8139\n",
    "\n",
    "# ADASYN: 밀도에 기반하여 샘플을 생성하는 방법\n",
    "adasyn = ADASYN(sampling_strategy='auto', random_state=RANDOM_STATE)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
    "    # F1 Score: 0.6205\n",
    "    # Recall: 0.6843\n",
    "    # Accuracy: 0.5798\n",
    "    # Precision: 0.5676\n",
    "\n",
    "# KMeansSMOTE: 클러스터링을 사용한 SMOTE 변형\n",
    "# cluster_balance_threshold를 낮추어, 더 적은 수의 소수 클래스 샘플이 있는 클러스터에서도 오버샘플링을 허용\n",
    "kmeans_smote = KMeansSMOTE(sampling_strategy='auto', random_state=RANDOM_STATE, cluster_balance_threshold=0.01)\n",
    "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
    "    # F1 Score: 0.9529\n",
    "    # Recall: 0.9618\n",
    "    # Accuracy: 0.9520\n",
    "    # Precision: 0.9442\n",
    "# kmeans_args 매개변수를 통해 클러스터의 수를 늘리거나 줄임\n",
    "kmeans_smote = KMeansSMOTE(sampling_strategy='auto', random_state=RANDOM_STATE, kmeans_estimator=20)\n",
    "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
    "    # F1 Score: 0.9726\n",
    "    # Recall: 0.9994\n",
    "    # Accuracy: 0.9716\n",
    "    # Precision: 0.9471\n",
    "#둘 다 적용\n",
    "kmeans_smote = KMeansSMOTE(sampling_strategy='auto', random_state=RANDOM_STATE, cluster_balance_threshold=0.01, kmeans_estimator=20)\n",
    "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
    "    # F1 Score: 0.9693\n",
    "    # Recall: 0.9954\n",
    "    # Accuracy: 0.9683\n",
    "    # Precision: 0.9445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9693\n",
      "Recall: 0.9954\n",
      "Accuracy: 0.9683\n",
      "Precision: 0.9445\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# Recursive Feature Elimination (RFE) for backward feature selection\n",
    "model = cb.CatBoostClassifier(\n",
    "    depth=6,\n",
    "    iterations=400,\n",
    "    l2_leaf_reg=5,\n",
    "    learning_rate=0.01,\n",
    "    verbose=0  # No output during training\n",
    ")\n",
    "\n",
    "# Train final model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test data\n",
    "test_data = pd.read_csv(os.path.join(ROOT_DIR, \"test_mod.csv\"))\n",
    "test_data = condition(test_data)\n",
    "\n",
    "# Scale the test data\n",
    "test_data[columns_to_scale] = scaler.transform(test_data[columns_to_scale])\n",
    "\n",
    "# Select the same features as the training data\n",
    "test_x_rfe = test_data[X_train.columns]\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(test_x_rfe)\n",
    "\n",
    "# Prepare submission\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = y_pred\n",
    "df_sub['target'] = df_sub['target'].map({1: 'Normal', 0: 'AbNormal'})\n",
    "\n",
    "# Calculate the ratio of abnormal cases\n",
    "counts = df_sub['target'].value_counts()\n",
    "ratio = counts['AbNormal'] / (counts['AbNormal'] + counts['Normal'])\n",
    "print(\"The ratio of abnormal is:\", ratio)\n",
    "\n",
    "# Save the submission file\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000] - D Loss: 1.2746, G Loss: 0.6387\n",
      "Epoch [1000/10000] - D Loss: 1.3296, G Loss: 0.6952\n",
      "Epoch [2000/10000] - D Loss: 1.3418, G Loss: 0.7197\n",
      "Epoch [3000/10000] - D Loss: 1.3839, G Loss: 0.7617\n",
      "Epoch [4000/10000] - D Loss: 1.3912, G Loss: 0.7099\n",
      "Epoch [5000/10000] - D Loss: 1.1336, G Loss: 1.1088\n",
      "Epoch [6000/10000] - D Loss: 0.9867, G Loss: 1.1017\n",
      "Epoch [7000/10000] - D Loss: 1.1094, G Loss: 0.5506\n",
      "Epoch [8000/10000] - D Loss: 1.0654, G Loss: 0.5339\n",
      "Epoch [9000/10000] - D Loss: 0.7271, G Loss: 2.1135\n",
      "F1 Score: 0.9713\n",
      "Recall: 0.9992\n",
      "Accuracy: 0.9703\n",
      "Precision: 0.9449\n",
      "The ratio of abnormal is: 0.0017856114279131386\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import catboost as cb\n",
    "\n",
    "# GAN 모델 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 데이터 전처리 및 GAN 학습\n",
    "ROOT_DIR = \"data\"\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(ROOT_DIR, \"train_mod.csv\"))\n",
    "\n",
    "def cat2num(X):\n",
    "    non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "    encoded_columns = {}\n",
    "\n",
    "    for column in non_numeric_columns:\n",
    "        encoder = LabelEncoder()\n",
    "        encoded_columns[column] = encoder.fit_transform(X[column])\n",
    "\n",
    "    encoded_df = pd.DataFrame(encoded_columns, index=X.index)\n",
    "    X = X.drop(columns=non_numeric_columns)\n",
    "    X = pd.concat([X, encoded_df], axis=1)\n",
    "\n",
    "    return X\n",
    "\n",
    "def condition(df):\n",
    "    df = cat2num(df)\n",
    "    \n",
    "    df['Condition1'] = df['Head Clean Position Z Collect Result_Dam'] <= 120\n",
    "    df['Condition1'] = df['Condition1'].astype(int)\n",
    "    \n",
    "    df['Condition2'] = (df['HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'] >= 284) & (df['HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'] >= 1000)\n",
    "    df['Condition2'] = df['Condition2'].astype(int)\n",
    "\n",
    "    try:\n",
    "        df = df[['Receip No Collect Result_Dam', \n",
    "                 '1st Pressure 1st Pressure Unit Time_AutoClave', \n",
    "                 '3rd Pressure Collect Result_AutoClave', \n",
    "                 'Chamber Temp. Unit Time_AutoClave', \n",
    "                 'Receip No Collect Result_Fill1', \n",
    "                 'Receip No Collect Result_Fill2',\n",
    "                 'Condition1', \n",
    "                 'Condition2',\n",
    "                 'target']]\n",
    "    except KeyError:\n",
    "        df = df[['Receip No Collect Result_Dam', \n",
    "                 '1st Pressure 1st Pressure Unit Time_AutoClave', \n",
    "                 '3rd Pressure Collect Result_AutoClave', \n",
    "                 'Chamber Temp. Unit Time_AutoClave', \n",
    "                 'Receip No Collect Result_Fill1', \n",
    "                 'Receip No Collect Result_Fill2',\n",
    "                 'Condition1', \n",
    "                 'Condition2']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data = condition(train_data)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = [col for col in train_data.columns if col != 'target']\n",
    "train_data[columns_to_scale] = scaler.fit_transform(train_data[columns_to_scale])\n",
    "\n",
    "# 소수 클래스 데이터만 사용하여 GAN 학습\n",
    "df_minority = train_data[train_data['target'] == 0]\n",
    "X_minority = df_minority.drop(columns=['target']).values\n",
    "df_majority = train_data[train_data['target'] == 1]\n",
    "\n",
    "input_dim = X_minority.shape[1]\n",
    "latent_dim = 16  # 잠재 공간의 차원\n",
    "\n",
    "generator = Generator(input_dim=latent_dim, output_dim=input_dim)\n",
    "discriminator = Discriminator(input_dim=input_dim)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "num_epochs = 10000\n",
    "batch_size = 64\n",
    "X_minority_tensor = torch.tensor(X_minority, dtype=torch.float32)\n",
    "data_loader = DataLoader(X_minority_tensor, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for real_samples in data_loader:\n",
    "        batch_size = real_samples.size(0)\n",
    "        \n",
    "        # 진짜 샘플에 대한 라벨은 1\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        # 가짜 샘플에 대한 라벨은 0\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "        # Discriminator 학습\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(real_samples)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        fake_samples = generator(z)\n",
    "        outputs = discriminator(fake_samples.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Generator 학습\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim)\n",
    "        fake_samples = generator(z)\n",
    "        outputs = discriminator(fake_samples)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] - D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# 다수 클래스 수에 맞춰 소수 클래스 오버샘플링\n",
    "num_majority = len(df_majority)\n",
    "num_minority_to_generate = num_majority - len(df_minority)\n",
    "\n",
    "z = torch.randn(num_minority_to_generate, latent_dim)\n",
    "generated_samples = generator(z).detach().numpy()\n",
    "generated_df = pd.DataFrame(generated_samples, columns=columns_to_scale)\n",
    "generated_df['target'] = 0\n",
    "\n",
    "# 원래 소수 클래스 데이터와 생성된 데이터를 결합\n",
    "oversampled_data = pd.concat([df_majority, df_minority, generated_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = oversampled_data.drop(columns=['target'])\n",
    "y = oversampled_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# CatBoost 모델 학습\n",
    "model = cb.CatBoostClassifier(\n",
    "    depth=6,\n",
    "    iterations=400,\n",
    "    l2_leaf_reg=5,\n",
    "    learning_rate=0.01,\n",
    "    verbose=0  # No output during training\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Test 데이터에 대한 처리 및 예측\n",
    "test_data = pd.read_csv(os.path.join(ROOT_DIR, \"test_mod.csv\"))\n",
    "test_data = condition(test_data)\n",
    "\n",
    "test_data[columns_to_scale] = scaler.transform(test_data[columns_to_scale])\n",
    "test_x = test_data[X_train.columns]\n",
    "\n",
    "y_pred = model.predict(test_x)\n",
    "\n",
    "# 제출 파일 준비\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = y_pred\n",
    "df_sub['target'] = df_sub['target'].map({1: 'Normal', 0: 'AbNormal'})\n",
    "\n",
    "# 비정상 케이스 비율 계산\n",
    "counts = df_sub['target'].value_counts()\n",
    "ratio = counts['AbNormal'] / (counts['AbNormal'] + counts['Normal'])\n",
    "print(\"The ratio of abnormal is:\", ratio)\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
